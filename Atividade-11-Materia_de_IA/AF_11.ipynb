{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Atividade #11: Indo Além (Hugging Face)"
      ],
      "metadata": {
        "id": "mT1dcRpoeT9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrantes: Jorge Mutran, kaick Nishiya, Lucas koiti, Lucas Prado, Lucas Quinto e Matheus Pestilli"
      ],
      "metadata": {
        "id": "6HsKoWB4gL8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 1: Tópico Escolhido\n",
        "Tópico: 1 RAG (Retrieved Augmented Generation)"
      ],
      "metadata": {
        "id": "kx_MKaUoayTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 2: Construção da Aplicação (Código Python)\n",
        "Vamos criar um \"Chatbot Especialista em Filmes\". Ele terá uma pequena base de conhecimento (que o modelo original não conhece necessariamente em detalhes) e usará RAG para responder."
      ],
      "metadata": {
        "id": "nUz3Ya76a8G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação das bibliotecas"
      ],
      "metadata": {
        "id": "0vGWlhCoZuhX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_OvbDv7AZjLq"
      },
      "outputs": [],
      "source": [
        "# Instalando as bibliotecas necessárias do ecossistema Hugging Face e vetores\n",
        "!pip install -q transformers sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " O Código da Aplicação RAG"
      ],
      "metadata": {
        "id": "n2aOO2aBZrJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import pipeline\n",
        "\n",
        "# --- 1. Base de Conhecimento (Simulando um banco de dados) ---\n",
        "# Texto fictício ou específico que o modelo deve consultar\n",
        "documents = [\n",
        "    \"O filme 'A Jornada do Dev' foi lançado em 2024 e conta a história de um programador que descobriu um bug na Matrix.\",\n",
        "    \"A linguagem de programação Python foi criada por Guido van Rossum e lançada em 1991.\",\n",
        "    \"Para instalar bibliotecas no Python, utilizamos o gerenciador de pacotes chamado pip.\",\n",
        "    \"O framework Hugging Face facilita o uso de modelos de Deep Learning para processamento de linguagem natural.\"\n",
        "]\n",
        "\n",
        "# --- 2. Indexação (Criando os Vetores) ---\n",
        "print(\"Criando embeddings...\")\n",
        "# Usamos um modelo leve e eficiente para transformar texto em números (embeddings)\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "doc_embeddings = encoder.encode(documents)\n",
        "\n",
        "# Criando o índice FAISS (Banco de dados vetorial em memória)\n",
        "d = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "# --- 3. Função de Busca (Retrieval) ---\n",
        "def search(query, k=1):\n",
        "    # Transforma a pergunta do usuário em vetor\n",
        "    query_vector = encoder.encode([query])\n",
        "    # Busca o vetor mais próximo na base de dados\n",
        "    distances, indices = index.search(query_vector, k)\n",
        "    return documents[indices[0][0]]\n",
        "\n",
        "# --- 4. Geração da Resposta (Generation) ---\n",
        "# Usamos o FLAN-T5, um modelo excelente do Google disponível no Hugging Face\n",
        "generator = pipeline('text2text-generation', model='google/flan-t5-base')\n",
        "\n",
        "def rag_chatbot(user_query):\n",
        "    print(f\"Pergunta: {user_query}\")\n",
        "\n",
        "    # Passo R (Retrieve): Busca a informação relevante\n",
        "    context = search(user_query)\n",
        "    print(f\"Contexto Encontrado: {context}\")\n",
        "\n",
        "    # Passo G (Generate): Gera a resposta baseada no contexto\n",
        "    # Prompt Engineering simples\n",
        "    prompt = f\"Context: {context}\\n\\nQuestion: {user_query}\\n\\nAnswer based on the context:\"\n",
        "\n",
        "    response = generator(prompt, max_length=100)[0]['generated_text']\n",
        "    return response\n",
        "\n",
        "# --- 5. Testando a Aplicação ---\n",
        "print(\"-\" * 50)\n",
        "# Pergunta sobre algo que está na nossa base fictícia\n",
        "resposta = rag_chatbot(\"Quando foi lançado o filme A Jornada do Dev?\")\n",
        "print(f\"Resposta da IA: {resposta}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "# Pergunta técnica baseada na base\n",
        "resposta_tec = rag_chatbot(\"Quem criou o Python?\")\n",
        "print(f\"Resposta da IA: {resposta_tec}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OWZDoIIvZsCW",
        "outputId": "b0a9d7b3-ee6b-4d2e-bf0a-7894c2a1f3a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Criando embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Pergunta: Quando foi lançado o filme A Jornada do Dev?\n",
            "Contexto Encontrado: O filme 'A Jornada do Dev' foi lançado em 2024 e conta a história de um programador que descobriu um bug na Matrix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resposta da IA: 2024\n",
            "--------------------------------------------------\n",
            "Pergunta: Quem criou o Python?\n",
            "Contexto Encontrado: A linguagem de programação Python foi criada por Guido van Rossum e lançada em 1991.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resposta da IA: Guido van Rossum\n"
          ]
        }
      ]
    }
  ]
}